{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0c7832b-3e77-4588-b28a-57dfa5ab3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pydub import AudioSegment\n",
    "import torch\n",
    "import torchaudio\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1f8b04e-07f9-4018-9c1b-b78bd6c8ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def load_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(f\"Cannot open video file {video_path}\")\n",
    "    return cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df701be6-bbd1-407b-b331-b38ab5af5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(cap):\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Изменение размера кадра\n",
    "        frame = cv2.resize(frame, (224, 224))\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b243d656-16ee-4b53-a3ac-4931699ce44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def extract_audio(video_path, audio_path):\n",
    "    video = AudioSegment.from_file(video_path)\n",
    "    video.export(audio_path, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bc60577-0d32-4233-8f39-8c4830f41855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def speech_to_text(audio_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio, language='ru-RU')\n",
    "    except sr.UnknownValueError:\n",
    "        text = \"\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b44bb07-6fe0-410f-b3d1-e5fdc19d407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "class SoundClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SoundClassifier, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(1, 16, kernel_size=3)\n",
    "        self.pool = torch.nn.MaxPool1d(2)\n",
    "        self.fc1 = torch.nn.Linear(16 * 49, 10)  # Предполагая, что входной размер 100\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 16 * 49)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "def classify_sound(audio_path, model):\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "    output = model(waveform)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    return predicted.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "485ef953-3212-46d3-98c1-29fa06393906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def detect_objects(frames):\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "    results = []\n",
    "    for frame in frames:\n",
    "        results.append(model(frame))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec9bff58-256a-45d8-b9d5-7e7dc3c8f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "def ocr_on_frame(frame):\n",
    "    text = pytesseract.image_to_string(Image.fromarray(frame), lang='rus')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a066bd70-1456-4eb0-8ca3-8c8a015304ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "def classify_scene(frames):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.eval()\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    results = []\n",
    "    for frame in frames:\n",
    "        input_tensor = preprocess(frame)\n",
    "        input_batch = input_tensor.unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_batch)\n",
    "        results.append(output)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bdd864a-2d20-430c-86cb-bae025a70623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, String\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker\n",
    "\n",
    "engine = create_engine('sqlite:///config.db')\n",
    "Base = declarative_base()\n",
    "\n",
    "class Keyword(Base):\n",
    "    __tablename__ = 'keywords'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    word = Column(String)\n",
    "\n",
    "Base.metadata.create_all(engine)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "def add_keyword(word):\n",
    "    keyword = Keyword(word=word)\n",
    "    session.add(keyword)\n",
    "    session.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b76eceb-6c15-4184-b5c4-039f2449e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/analyze_video/\")\n",
    "async def analyze_video_endpoint(video_path: str):\n",
    "    # Логика обработки видео\n",
    "    return {\"status\": \"Video analysis started\"}\n",
    "\n",
    "# Запуск сервера:\n",
    "# uvicorn main:app --reload\n",
    "@app.get(\"/search/\")\n",
    "async def search_endpoint(query: str):\n",
    "    # Логика поиска по метаданным\n",
    "    return {\"results\": []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1fd090d-1ace-467d-810d-e43131bf30c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40497/2086966776.py:1: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.AnalysisResult, and will be replaced in the string-lookup table.\n",
      "  class AnalysisResult(Base):\n"
     ]
    }
   ],
   "source": [
    "class AnalysisResult(Base):\n",
    "    __tablename__ = 'analysis_results'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    video_path = Column(String)\n",
    "    datameta = Column(String)\n",
    "\n",
    "def save_result(video_path, datameta):\n",
    "    result = AnalysisResult(video_path=video_path, metadata=metadata)\n",
    "    session.add(result)\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d53cfb8-804d-4751-927c-314fe49e6a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    results = session.query(AnalysisResult).all()\n",
    "    return render_template('index.html', results=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bf6f74e-d9b6-4f47-8579-361f0e2d3f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(video_path):\n",
    "    cap = load_video(video_path)\n",
    "    frames = extract_frames(cap)\n",
    "    audio_path = 'temp_audio.wav'\n",
    "    extract_audio(video_path, audio_path)\n",
    "\n",
    "    # Анализ аудио\n",
    "    speech_text = speech_to_text(audio_path)\n",
    "    sound_class = classify_sound(audio_path, sound_model)\n",
    "\n",
    "    # Анализ видео\n",
    "    objects = detect_objects(frames)\n",
    "    ocr_texts = [ocr_on_frame(frame) for frame in frames]\n",
    "    scenes = classify_scene(frames)\n",
    "\n",
    "    # Сохранение результатов\n",
    "    metadata = {\n",
    "        \"speech_text\": speech_text,\n",
    "        \"sound_class\": sound_class,\n",
    "        \"objects\": objects,\n",
    "        \"ocr_texts\": ocr_texts,\n",
    "        \"scenes\": scenes,\n",
    "    }\n",
    "    save_result(video_path, str(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c3061e9-8668-4282-8038-75f570e8e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sound_classifier(data_loader, model, criterion, optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0972bbbf-d8ce-47b2-a280-44aefdfae6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_object_detection_model(model, data_loader):\n",
    "    model.train()\n",
    "    for images, targets in data_loader:\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6573b3ed-425b-4fe4-9229-33f233cd52a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main(\"example.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5d062d-f25e-4995-b474-45cd49d3dda4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
