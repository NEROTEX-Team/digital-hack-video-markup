{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b6a0b9-43fe-4c94-a72c-a20770563057",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:22:52.298233Z",
     "iopub.status.busy": "2024-09-29T05:22:52.297167Z",
     "iopub.status.idle": "2024-09-29T05:23:01.904966Z",
     "shell.execute_reply": "2024-09-29T05:23:01.904294Z",
     "shell.execute_reply.started": "2024-09-29T05:22:52.298187Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import speech_recognition as sr\n",
    "from sqlalchemy import create_engine, Column, Integer, String\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Укажите путь к tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "614aed3d-5cb1-4067-97b9-9ac6ca767cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:23:01.907171Z",
     "iopub.status.busy": "2024-09-29T05:23:01.906099Z",
     "iopub.status.idle": "2024-09-29T05:23:01.924257Z",
     "shell.execute_reply": "2024-09-29T05:23:01.923586Z",
     "shell.execute_reply.started": "2024-09-29T05:23:01.907127Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(f\"Cannot open video file {video_path}\")\n",
    "    return cap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab904a1-e701-4135-91cc-9216c002d9e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:23:01.925785Z",
     "iopub.status.busy": "2024-09-29T05:23:01.925033Z",
     "iopub.status.idle": "2024-09-29T05:23:01.943076Z",
     "shell.execute_reply": "2024-09-29T05:23:01.942438Z",
     "shell.execute_reply.started": "2024-09-29T05:23:01.925752Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_frames(cap):\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Изменение размера кадра\n",
    "        frame = cv2.resize(frame, (224, 224))\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c917a2a0-6142-4f22-8747-c83a03d9e5e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:23:01.945375Z",
     "iopub.status.busy": "2024-09-29T05:23:01.944570Z",
     "iopub.status.idle": "2024-09-29T05:23:01.992406Z",
     "shell.execute_reply": "2024-09-29T05:23:01.991709Z",
     "shell.execute_reply.started": "2024-09-29T05:23:01.945336Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def extract_audio(video_path, audio_path):\n",
    "    video = AudioSegment.from_file(video_path)\n",
    "    video.export(audio_path, format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e08339d7-0485-437b-bf2b-d01faf5b8325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:23:01.993914Z",
     "iopub.status.busy": "2024-09-29T05:23:01.993251Z",
     "iopub.status.idle": "2024-09-29T05:23:02.053774Z",
     "shell.execute_reply": "2024-09-29T05:23:02.053047Z",
     "shell.execute_reply.started": "2024-09-29T05:23:01.993885Z"
    }
   },
   "outputs": [],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "import wave\n",
    "import json\n",
    "\n",
    "def speech_to_text_vosk(audio_path):\n",
    "    model = Model('vosk-model-small-ru-0.22')  # Загрузите модель и укажите путь\n",
    "    wf = wave.open(audio_path, \"rb\")\n",
    "    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "        # Преобразование аудио в требуемый формат\n",
    "        sound = AudioSegment.from_file(audio_path)\n",
    "        sound = sound.set_channels(1)\n",
    "        sound = sound.set_sample_width(2)\n",
    "        sound.export(\"temp_audio.wav\", format=\"wav\")\n",
    "        wf = wave.open(\"temp_audio.wav\", \"rb\")\n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "    text = \"\"\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            res = json.loads(rec.Result())\n",
    "            text += res.get('text', '') + \" \"\n",
    "    res = json.loads(rec.FinalResult())\n",
    "    text += res.get('text', '')\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0b96f57-6171-4282-9bcd-b20dfb44b15c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:23:02.055887Z",
     "iopub.status.busy": "2024-09-29T05:23:02.054793Z",
     "iopub.status.idle": "2024-09-29T05:23:02.107965Z",
     "shell.execute_reply": "2024-09-29T05:23:02.107350Z",
     "shell.execute_reply.started": "2024-09-29T05:23:02.055840Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 сверточный слой с padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 сверточный слой\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes ,stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock поддерживает только groups=1 и base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 не поддерживается в BasicBlock\")\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Оба слоя self.conv2 и self.downsample уменьшают размерность входа, когда stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class NetVLAD(nn.Module):\n",
    "    \"\"\"Реализация слоя NetVLAD\"\"\"\n",
    "\n",
    "    def __init__(self, num_clusters=16, dim=512, alpha=100.0,\n",
    "                 normalize_input=True):\n",
    "        super(NetVLAD, self).__init__()\n",
    "        self.num_clusters = num_clusters\n",
    "        self.dim = dim\n",
    "        self.alpha = alpha\n",
    "        self.normalize_input = normalize_input\n",
    "        self.conv = nn.Conv2d(dim, num_clusters, kernel_size=(1, 1), bias=True)\n",
    "        self.centroids = nn.Parameter(torch.rand(num_clusters, dim))\n",
    "        self._init_params()\n",
    "\n",
    "    def _init_params(self):\n",
    "        self.conv.weight = nn.Parameter(\n",
    "            (2.0 * self.alpha * self.centroids).unsqueeze(-1).unsqueeze(-1)\n",
    "        )\n",
    "        self.conv.bias = nn.Parameter(\n",
    "            - self.alpha * self.centroids.norm(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C = x.shape[:2]\n",
    "\n",
    "        if self.normalize_input:\n",
    "            x = F.normalize(x, p=2, dim=1)  # Нормализация по размерности дескриптора\n",
    "\n",
    "        # soft-assignment\n",
    "        soft_assign = self.conv(x).view(N, self.num_clusters, -1)\n",
    "        soft_assign = F.softmax(soft_assign, dim=1)\n",
    "\n",
    "        x_flatten = x.view(N, C, -1)\n",
    "        \n",
    "        # Вычисление резидуалов к каждому кластеру\n",
    "        residual = x_flatten.expand(self.num_clusters, -1, -1, -1).permute(1, 0, 2, 3) - \\\n",
    "            self.centroids.expand(x_flatten.size(-1), -1, -1).permute(1, 2, 0).unsqueeze(0)\n",
    "        residual *= soft_assign.unsqueeze(2)\n",
    "        vlad = residual.sum(dim=-1)\n",
    "\n",
    "        vlad = F.normalize(vlad, p=2, dim=2)  # Внутренняя нормализация\n",
    "        vlad = vlad.view(x.size(0), -1)  # Выпрямление\n",
    "        vlad = F.normalize(vlad, p=2, dim=1)  # L2 нормализация\n",
    "\n",
    "        return vlad\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, pool='avgpool', zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.pool = pool\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # Каждый элемент в кортеже указывает, следует ли заменить 2x2 stride на дилатированную свертку\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation должно быть None или кортежем из 3 элементов\")\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)  # Изменено на 1 канал\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        if self.pool == 'avgpool':\n",
    "            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "            self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        elif self.pool == 'vlad':\n",
    "            self.avgpool = NetVLAD()\n",
    "            self.fc = nn.Linear(8192 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.normal_(m.weight, mean=1, std=0.02)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Инициализация нулями последнего BN в каждом резидуальном блоке\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                    conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                    norm_layer(planes * block.expansion),\n",
    "                )\n",
    "           \n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # [B, 64, H/2, W/2]\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)  # [B, 64, H/4, W/4]\n",
    "\n",
    "        x = self.layer1(x)  # [B, 64, H/4, W/4]\n",
    "        x = self.layer2(x)  # [B, 128, H/8, W/8]\n",
    "        x = self.layer3(x)  # [B, 256, H/16, W/16]\n",
    "        x = self.layer4(x)  # [B, 512, H/32, W/32]\n",
    "        \n",
    "        if self.pool == 'avgpool':\n",
    "            x = self.avgpool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc(x)\n",
    "        elif self.pool == 'vlad':\n",
    "            x = self.avgpool(x)\n",
    "            x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    # Если нужно загрузить предобученные веса, добавьте код здесь\n",
    "    if pretrained:\n",
    "        state_dict = torch.hub.load_state_dict_from_url(\n",
    "            model_urls[arch], progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-f37072fd.pth',\n",
    "    # Добавьте другие ссылки на модели, если нужно\n",
    "}\n",
    "\n",
    "def resnet18(pretrained=False, progress=True, **kwargs):\n",
    "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "# Добавьте другие функции resnet, если необходимо\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "928ec3e5-5ff9-4027-ae19-2108eb506611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:23:02.109760Z",
     "iopub.status.busy": "2024-09-29T05:23:02.108829Z",
     "iopub.status.idle": "2024-09-29T05:23:02.141080Z",
     "shell.execute_reply": "2024-09-29T05:23:02.140485Z",
     "shell.execute_reply.started": "2024-09-29T05:23:02.109722Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_sound_model(model_path=None, num_classes=10, device='cpu'):\n",
    "    # Загрузка предобученной модели ResNet18\n",
    "    model = resnet18(pretrained=True)\n",
    "    \n",
    "    # Модификация первого сверточного слоя для принятия 1 канала\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    \n",
    "    # Корректировка весов для conv1\n",
    "    pretrained_conv1_weight = model.state_dict()['conv1.weight']\n",
    "    \n",
    "    # Усреднение весов по каналам\n",
    "    new_conv1_weight = pretrained_conv1_weight.mean(dim=1, keepdim=True)\n",
    "    \n",
    "    # Присвоение скорректированных весов\n",
    "    model.conv1.weight.data = new_conv1_weight\n",
    "    \n",
    "    # Замена полносвязного слоя для соответствия количеству классов\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    \n",
    "    # Загрузка сохраненной модели, если она указана\n",
    "    if model_path:\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        \n",
    "        # Удаление несовместимых ключей\n",
    "        incompatible_keys = ['conv1.weight', 'fc.weight', 'fc.bias']\n",
    "        for key in incompatible_keys:\n",
    "            if key in state_dict:\n",
    "                del state_dict[key]\n",
    "                print(f\"Removed {key} from state_dict due to size mismatch.\")\n",
    "        \n",
    "        # Загрузка state_dict с strict=False\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db45898-31c5-49e7-8292-5b3592e6df4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:23:02.142313Z",
     "iopub.status.busy": "2024-09-29T05:23:02.141827Z",
     "iopub.status.idle": "2024-09-29T05:23:02.171253Z",
     "shell.execute_reply": "2024-09-29T05:23:02.170504Z",
     "shell.execute_reply.started": "2024-09-29T05:23:02.142263Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_sound(audio_path, model, device='cpu'):\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "    \n",
    "    # Preprocess the audio waveform\n",
    "    resample_rate = 16000\n",
    "    if sample_rate != resample_rate:\n",
    "        resampler = T.Resample(orig_freq=sample_rate, new_freq=resample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "    \n",
    "    # Convert to Mel spectrogram\n",
    "    n_mels = 128\n",
    "    mel_spectrogram = T.MelSpectrogram(\n",
    "        sample_rate=resample_rate,\n",
    "        n_fft=2048,\n",
    "        hop_length=512,\n",
    "        n_mels=n_mels\n",
    "    )\n",
    "    mel_spec = mel_spectrogram(waveform)\n",
    "    mel_spec_db = T.AmplitudeToDB()(mel_spec)\n",
    "    \n",
    "    # Normalize\n",
    "    mel_spec_db = (mel_spec_db - mel_spec_db.mean()) / mel_spec_db.std()\n",
    "    \n",
    "    # Add batch and channel dimensions\n",
    "    input_tensor = mel_spec_db.unsqueeze(0).to(device)  # Shape: [1, 1, n_mels, time_steps]\n",
    "    \n",
    "    # Classification\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    \n",
    "    return predicted_class, probabilities.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42ec096f-48af-4c00-8b3c-f86f1d108f74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:23:02.173102Z",
     "iopub.status.busy": "2024-09-29T05:23:02.172426Z",
     "iopub.status.idle": "2024-09-29T05:23:02.191300Z",
     "shell.execute_reply": "2024-09-29T05:23:02.190643Z",
     "shell.execute_reply.started": "2024-09-29T05:23:02.173068Z"
    }
   },
   "outputs": [],
   "source": [
    "def detect_objects(frames):\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "    results = []\n",
    "    for frame in frames:\n",
    "        # Получение результатов детекции\n",
    "        result = model(frame)\n",
    "        # Преобразование результатов в формат JSON\n",
    "        result_json = result.pandas().xyxy[0].to_json(orient=\"records\")\n",
    "        results.append(json.loads(result_json))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c03f9b55-8bee-41ac-967c-99102138c68e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:23:02.194226Z",
     "iopub.status.busy": "2024-09-29T05:23:02.193570Z",
     "iopub.status.idle": "2024-09-29T05:23:02.215011Z",
     "shell.execute_reply": "2024-09-29T05:23:02.214267Z",
     "shell.execute_reply.started": "2024-09-29T05:23:02.194190Z"
    }
   },
   "outputs": [],
   "source": [
    "def ocr_on_frame(frame):\n",
    "    text = pytesseract.image_to_string(Image.fromarray(frame), lang='rus')\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a4e9ffd-545a-41d3-b505-0ca0cefb81a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:23:02.216552Z",
     "iopub.status.busy": "2024-09-29T05:23:02.215796Z",
     "iopub.status.idle": "2024-09-29T05:23:02.989024Z",
     "shell.execute_reply": "2024-09-29T05:23:02.988225Z",
     "shell.execute_reply.started": "2024-09-29T05:23:02.216521Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "def classify_scene(frames):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.eval()\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    results = []\n",
    "    for frame in frames:\n",
    "        input_tensor = preprocess(frame)\n",
    "        input_batch = input_tensor.unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_batch)\n",
    "        probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "        results.append(predicted_class)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6336d278-d717-4042-936e-275f093703ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:23:02.991159Z",
     "iopub.status.busy": "2024-09-29T05:23:02.990042Z",
     "iopub.status.idle": "2024-09-29T05:23:03.108261Z",
     "shell.execute_reply": "2024-09-29T05:23:03.107517Z",
     "shell.execute_reply.started": "2024-09-29T05:23:02.991123Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///config.db')\n",
    "Base = declarative_base()\n",
    "\n",
    "class Keyword(Base):\n",
    "    __tablename__ = 'keywords'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    word = Column(String)\n",
    "\n",
    "class AnalysisResult(Base):\n",
    "    __tablename__ = 'analysis_results'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    video_path = Column(String)\n",
    "    data = Column(String)\n",
    "\n",
    "Base.metadata.create_all(engine)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "def add_keyword(word):\n",
    "    keyword = Keyword(word=word)\n",
    "    session.add(keyword)\n",
    "    session.commit()\n",
    "\n",
    "def save_result(video_path, data):\n",
    "    result = AnalysisResult(video_path=video_path, data=data)\n",
    "    session.add(result)\n",
    "    session.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "448e93ed-4271-4e41-844f-d058a3242aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:23:03.110066Z",
     "iopub.status.busy": "2024-09-29T05:23:03.109096Z",
     "iopub.status.idle": "2024-09-29T05:23:03.689427Z",
     "shell.execute_reply": "2024-09-29T05:23:03.688729Z",
     "shell.execute_reply.started": "2024-09-29T05:23:03.110028Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/analyze_video/\")\n",
    "async def analyze_video_endpoint(video_path: str):\n",
    "    # Здесь вызывается функция main для обработки видео\n",
    "    main(video_path)\n",
    "    return {\"status\": \"Video analysis started\"}\n",
    "\n",
    "@app.get(\"/search/\")\n",
    "async def search_endpoint(query: str):\n",
    "    # Поиск по базе данных\n",
    "    results = session.query(AnalysisResult).filter(AnalysisResult.metadata.contains(query)).all()\n",
    "    return {\"results\": [result.metadata for result in results]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d42d708-8a22-4471-b838-5ef0e808bf15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:23:03.690677Z",
     "iopub.status.busy": "2024-09-29T05:23:03.690320Z",
     "iopub.status.idle": "2024-09-29T05:23:03.967103Z",
     "shell.execute_reply": "2024-09-29T05:23:03.966412Z",
     "shell.execute_reply.started": "2024-09-29T05:23:03.690648Z"
    }
   },
   "outputs": [],
   "source": [
    "from flask import Flask, render_template\n",
    "\n",
    "app_flask = Flask(__name__)\n",
    "\n",
    "@app_flask.route('/')\n",
    "def index():\n",
    "    results = session.query(AnalysisResult).all()\n",
    "    return render_template('index.html', results=results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63d91e1c-2344-4b93-8a2e-d194e186c6aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:23:03.968855Z",
     "iopub.status.busy": "2024-09-29T05:23:03.967981Z",
     "iopub.status.idle": "2024-09-29T05:23:03.989162Z",
     "shell.execute_reply": "2024-09-29T05:23:03.988580Z",
     "shell.execute_reply.started": "2024-09-29T05:23:03.968817Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def process_video(video_path):\n",
    "    logger.info(f\"Starting processing for {video_path}\")\n",
    "    # Логика обработки\n",
    "    logger.info(f\"Finished processing for {video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04e07dd0-19d3-4a18-9b77-fd4695436b9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:23:03.991485Z",
     "iopub.status.busy": "2024-09-29T05:23:03.990115Z",
     "iopub.status.idle": "2024-09-29T05:23:04.041582Z",
     "shell.execute_reply": "2024-09-29T05:23:04.040872Z",
     "shell.execute_reply.started": "2024-09-29T05:23:03.991449Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(video_path):\n",
    "    cap = load_video(video_path)\n",
    "    frames = extract_frames(cap)\n",
    "    audio_path = 'temp_audio.wav'\n",
    "    extract_audio(video_path, audio_path)\n",
    "\n",
    "    # Analyze audio\n",
    "    speech_text = speech_to_text_vosk(audio_path)\n",
    "\n",
    "    # Load the sound classification model\n",
    "    num_classes = 10  # Update with your actual number of classes\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #sound_model = load_sound_model(num_classes=num_classes, device=device)\n",
    "    #sound_class, sound_probabilities = classify_sound(audio_path, sound_model, device)\n",
    "    \n",
    "    # Analyze video\n",
    "    objects = detect_objects(frames)\n",
    "    ocr_texts = [ocr_on_frame(frame) for frame in frames]\n",
    "    scenes = classify_scene(frames)\n",
    "\n",
    "    # Save results\n",
    "    metadata = {\n",
    "        \"speech_text\": speech_text,\n",
    "        \"sound_class\": int(sound_class),\n",
    "        \"objects\": objects,\n",
    "        \"ocr_texts\": ocr_texts,\n",
    "        \"scenes\": scenes,\n",
    "    }\n",
    "    save_result(video_path, str(metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ccdce79-5d3f-4a63-931c-a4be5641df97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TesseractNotFoundError",
     "evalue": "/usr/bin/tesseract is not installed or it's not in your PATH. See README file for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msubprocess_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    972\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1862\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/bin/tesseract'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTesseractNotFoundError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2668/2163667583.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_video_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/jupyter/datasphere/project/example.mp4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_video_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2668/2791170038.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Analyze video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mobjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mocr_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mocr_on_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mscenes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_scene\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2668/2791170038.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Analyze video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mobjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mocr_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mocr_on_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mscenes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_scene\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2668/1565510429.py\u001b[0m in \u001b[0;36mocr_on_frame\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mocr_on_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rus'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m     return {\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m     }[output_type]()\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    350\u001b[0m         }\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mrun_tesseract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         return _read_output(\n\u001b[1;32m    354\u001b[0m             \u001b[0;34mf\"{kwargs['output_filename_base']}{extsep}{extension}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTesseractNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtimeout_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTesseractNotFoundError\u001b[0m: /usr/bin/tesseract is not installed or it's not in your PATH. See README file for more information."
     ]
    }
   ],
   "source": [
    "# Укажите путь к вашему тестовому видео\n",
    "test_video_path = '/home/jupyter/datasphere/project/example.mp4'\n",
    "\n",
    "main(test_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4109354e-f9e8-4660-a4e9-7d0da50598fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=10, device='cpu'):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            # inputs должны иметь форму [batch_size, 1, height, width]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Дополнительно: оценка на валидационном наборе\n",
    "    \n",
    "    # Сохранение обученной модели\n",
    "    torch.save(model.state_dict(), 'sound_classification_resnet.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392ee25b-21d5-42b7-a8d6-207402f6a860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468ecb2f-3d55-451d-8427-61aa559e36c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
